{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f136c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8698b994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip install -q xarray netCDF4 cftime\n",
    "!pip install -q xesmf  # Optional, will fallback to basic interpolation if fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75be243c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the src folder to Google Drive, then add to path\n",
    "import sys\n",
    "sys.path.insert(0, '/content/drive/MyDrive/Downscaling ML CEP')\n",
    "\n",
    "from src.data.preprocessors import ClimateDataPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2952cdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "BASE_PATH = '/content/drive/MyDrive/Downscaling ML CEP/AI_GCMs'\n",
    "OUTPUT_DIR = '/content/drive/MyDrive/Downscaling ML CEP/data/processed/train'\n",
    "\n",
    "print(f\"Data path: {BASE_PATH}\")\n",
    "print(f\"Output path: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f303bf6",
   "metadata": {},
   "source": [
    "## Option 1: Process ALL GCMs (Recommended)\n",
    "\n",
    "This will process all 9 GCMs. Takes ~10-15 minutes on Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6877a25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessor\n",
    "preprocessor = ClimateDataPreprocessor(\n",
    "    base_path=BASE_PATH,\n",
    "    start_year=1980,\n",
    "    end_year=2014\n",
    ")\n",
    "\n",
    "# Process all GCMs\n",
    "output_path = preprocessor.process_and_save(output_dir=OUTPUT_DIR)\n",
    "\n",
    "print(f\"\\n✓ All preprocessing complete!\")\n",
    "print(f\"✓ Files saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976e859f",
   "metadata": {},
   "source": [
    "## Option 2: Process Single GCM (Quick Test)\n",
    "\n",
    "Test with just one GCM first. Takes ~2-3 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d910e61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessor\n",
    "preprocessor = ClimateDataPreprocessor(\n",
    "    base_path=BASE_PATH,\n",
    "    start_year=1980,\n",
    "    end_year=2014\n",
    ")\n",
    "\n",
    "# Process only BCC-CSM2-MR for quick test\n",
    "output_path = preprocessor.process_and_save(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    gcm_models=['BCC-CSM2-MR']  # Just one GCM\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Single GCM test complete!\")\n",
    "print(f\"✓ Files saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b87dde",
   "metadata": {},
   "source": [
    "## Verify Output Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad421e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "\n",
    "output_path = Path(OUTPUT_DIR)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PROCESSED FILES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# List all NetCDF files\n",
    "nc_files = sorted(output_path.glob('*.nc'))\n",
    "\n",
    "for i, file in enumerate(nc_files, 1):\n",
    "    print(f\"\\n[{i}] {file.name}\")\n",
    "    \n",
    "    # Quick inspection\n",
    "    ds = xr.open_dataset(file)\n",
    "    print(f\"    Variables: {list(ds.data_vars)}\")\n",
    "    print(f\"    Dimensions: {dict(ds.dims)}\")\n",
    "    print(f\"    Time range: {ds.time.values[0]} to {ds.time.values[-1]}\")\n",
    "    \n",
    "    # Check shapes\n",
    "    for var in ds.data_vars:\n",
    "        print(f\"    {var}: {ds[var].shape}\")\n",
    "    \n",
    "    ds.close()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Total files: {len(nc_files)}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1971e2",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "After preprocessing completes successfully:\n",
    "\n",
    "1. **Feature Engineering**: Run `src/data/loaders.py` to create training DataFrames\n",
    "2. **Model Training**: Run `src/models/train.py` to train ML models\n",
    "3. **Complete Workflow**: Use `notebooks/02_complete_workflow.ipynb` for end-to-end execution\n",
    "\n",
    "Expected files after full preprocessing:\n",
    "- `cru_1980_2014.nc` (1 file)\n",
    "- `era5_1980_2014.nc` (1 file)\n",
    "- `{GCM_name}_hist_1980_2014.nc` (9 files, one per GCM)\n",
    "\n",
    "**Total: 11 NetCDF files ready for training**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
